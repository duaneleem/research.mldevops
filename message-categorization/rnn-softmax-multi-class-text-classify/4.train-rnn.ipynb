{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257cb286-8a11-4fe9-866a-acebb1b41e07",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "We will use Recurrent Neural Network (LSTM) and softmax to have a list of label predictions.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Output file from 1-preprocess-data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab13ef-1e83-4152-9cff-7628062ac635",
   "metadata": {},
   "source": [
    "# Install Dependencies\n",
    "\n",
    "Our environment will need several ML packages required to import."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3233a63-fdc9-4200-b8df-e49aa8f63029",
   "metadata": {},
   "source": [
    "## PIP Packages (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85e16ce-4632-466d-875a-a0824faf2621",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.20.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.29.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.18.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (22.12.6)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165f7ec-2cad-47c8-907c-2c340681f155",
   "metadata": {},
   "source": [
    "## Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326d54b7-76ed-448c-a3a8-e7792aff5a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 22:08:17.531117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-07 22:08:18.167424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-07 22:08:18.167471: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-07 22:08:19.852766: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-07 22:08:19.852907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-07 22:08:19.852917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71236f-394d-464f-a430-76c5f1a2e183",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e695913-3345-4fc9-a9f8-a187790a5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "file_path = 'data/output/3-merge-data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Tokenize and pad the text data\n",
    "max_len = 100  # Maximum length of input sequences\n",
    "vocab_size = 10000  # Vocabulary size\n",
    "\n",
    "# Training Settings\n",
    "epochsCount = 4\n",
    "epochsShuffleData = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d7e20-86c5-4e85-9d11-ee7c31a3905c",
   "metadata": {},
   "source": [
    "# Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a974b09-c291-4684-903d-fdd0c2f9fd0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle NaN values\n",
    "df = df.dropna(subset=['singleMessage'])\n",
    "\n",
    "# Extract features and target\n",
    "X = df['singleMessage']\n",
    "y = df['reason']\n",
    "\n",
    "# Split the dataset into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y)  # Fit on the entire dataset\n",
    "\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test_categorical = to_categorical(y_test_encoded, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21a7bf-35e7-4177-b1bc-b965ac0effdb",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "We will shuffle our data per each epoch.  We want a list of label probabilities so we will be using softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3b77c4-5aed-47b4-b8fe-d654f8f026a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 22:08:25.882348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-07 22:08:25.883175: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-07 22:08:25.883211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ba1c25b27f4f): /proc/driver/nvidia/version does not exist\n",
      "2023-06-07 22:08:25.885147: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2872/2872 [==============================] - 295s 101ms/step - loss: 0.2811 - accuracy: 0.9282 - val_loss: 0.2046 - val_accuracy: 0.9464\n",
      "Epoch 2/4\n",
      "2872/2872 [==============================] - 291s 101ms/step - loss: 0.1509 - accuracy: 0.9573 - val_loss: 0.1612 - val_accuracy: 0.9506\n",
      "Epoch 3/4\n",
      "2872/2872 [==============================] - 321s 112ms/step - loss: 0.1111 - accuracy: 0.9669 - val_loss: 0.1667 - val_accuracy: 0.9517\n",
      "Epoch 4/4\n",
      "2872/2872 [==============================] - 331s 115ms/step - loss: 0.0957 - accuracy: 0.9714 - val_loss: 0.1769 - val_accuracy: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f080ef26370>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Create the RNN model\n",
    "embedding_dim = 128\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, y_train_categorical, epochs=epochsCount, validation_data=(X_test_padded, y_test_categorical), shuffle=epochsShuffleData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605b095-b899-435e-b91d-6853b3620eed",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Get a list of label probabilities based on the message we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3d6852-fa94-4036-bb30-26572f5fdf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Politics not allowed outside of references to the market.: 0.9955\n",
      "Clean: 0.0041\n",
      "Off-topic: 0.0002\n",
      "Inappropriate comment.: 0.0001\n",
      "Personal or sensitive information not allowed in chat.: 0.0001\n",
      "Third-party links / content not allowed.: 0.0000\n",
      "Caps for tickers only.: 0.0000\n",
      "password: 0.0000\n",
      "Bypassing the chat filters is not allowed.: 0.0000\n",
      "Not sure what this is: 0.0000\n",
      "False information or no source.: 0.0000\n",
      "language please: 0.0000\n",
      "outside link: 0.0000\n",
      "False or misleading information, or no source.: 0.0000\n",
      "False information.: 0.0000\n",
      "Reviewed by admin internally; not necessary to post to public chat.: 0.0000\n",
      "Might be searching for offline contact: 0.0000\n",
      "Account number visible. Please remove from content before reposting.: 0.0000\n",
      "Bullying a member or moderator.: 0.0000\n",
      "Please provide more information when making comments like these. For example \"AFRM is being shorted every candle, so I think it's manipulated\" : 0.0000\n",
      "Support Room would be more appropriate for this inquiry.: 0.0000\n",
      "CMEG complaint: 0.0000\n",
      "competitor : 0.0000\n",
      "no advice: 0.0000\n",
      "English only please!: 0.0000\n",
      "gray area: 0.0000\n",
      "Discord is not an allowed word in the room. Please don't bypass the filter : 0.0000\n",
      "Perv is an inappropriate term please refrain from these kinds of discussions here: 0.0000\n",
      "possible password: 0.0000\n",
      "talking about drugs : 0.0000\n",
      "No reference to 3rd party contact: 0.0000\n",
      "\"Any discussion related in any way to market manipulation is strictly prohibited, as is advising others on whether to buy, sell, or hold.\": 0.0000\n",
      "comments about market manipulation not allowed even if joking: 0.0000\n",
      "Language: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Example message to predict\n",
    "new_message = [\"fuck you\"]\n",
    "\n",
    "# Preprocess the new message\n",
    "new_message_seq = tokenizer.texts_to_sequences(new_message)\n",
    "new_message_padded = pad_sequences(new_message_seq, maxlen=max_len)\n",
    "\n",
    "# Predict the class probabilities\n",
    "class_probabilities = model.predict(new_message_padded)\n",
    "\n",
    "# Sort the class probabilities in descending order along with their corresponding classes\n",
    "sorted_probabilities = sorted(zip(label_encoder.classes_, class_probabilities[0]), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted class probabilities\n",
    "for reason, probability in sorted_probabilities:\n",
    "    print(f\"{reason}: {probability:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35292a-6e59-4e4b-907f-0b831e0d7a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
