{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db9b77c-964f-407e-b8f9-eecc643c0e26",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "We will be doing the following to create a Deep Neural Network using RNN and Softmax as the activation output layer:\n",
    "\n",
    "- Instantiate required Python components.\n",
    "- Set Hyperparameters\n",
    "- Read the CSV data\n",
    "- Remove unused fields.\n",
    "- Keep only the message in the JSON.\n",
    "- Define two lists: messages and labels.\n",
    "- Split data between training and validation sets.\n",
    "- Tokenize words\n",
    "- Pad sequences so they are the same size.\n",
    "- Build LSTM\n",
    "- Train several epochs.\n",
    "- Plot Loss and Accuracy to view model's performance.\n",
    "- Make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07974922-a04d-4d27-a4e1-2e059136e330",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Instantiate required Python components.\n",
    "\n",
    "Our project will use TensorFlow for developing our model.  We'll also need several other Python libraries to work with our CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e8ed13-8ce2-42f3-a1e2-31e9c62f6bfe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 03:14:18.949107: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-01 03:14:19.056076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-01 03:14:19.056101: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-01 03:14:19.648119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-01 03:14:19.648290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-01 03:14:19.648303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0610d5-1a17-47e6-ac18-706fd3aa2afa",
   "metadata": {},
   "source": [
    "# Set Hyperparameters\n",
    "\n",
    "This handy section will control all the important parameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0bb137-dda7-49bf-ac86-7926304b5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 64\n",
    "max_length = 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = ''\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26d097-d838-40df-869c-f350e359a3c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read the CSV data\n",
    "\n",
    "Read the CSV contents and keep only specific fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66cb8ec1-9ab0-4bc6-8b3f-819f0f485252",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "messages = []\n",
    "\n",
    "# Open file and save to dataframe.\n",
    "df = pd.read_csv(\"./rnn-softmax-multi-class-text-classify/data/20221220-message-incidents.csv\")\n",
    "\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aef30a-f913-4427-80ee-b8f9fff9931d",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "\n",
    "As part of the Machine Learning process, we will remove fields not required, fix missing values, remove noisy data, and any additional steps to prepare for the ML training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb0ac4-2b12-4db2-9895-b49c5223f0e4",
   "metadata": {},
   "source": [
    "## Keep Labels and Messages\n",
    "\n",
    "We will keep only specific columns that is important to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287fb391-1c0d-4299-94b6-c80f1592badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reason', 'messages'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Keep specific columns.\n",
    "df = df[[\"reason\", \"messages\"]]\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fd4f1-1613-4358-add6-7b7023c0987a",
   "metadata": {},
   "source": [
    "## ▶️ Remove Empty Messages Data\n",
    "\n",
    "Let's remove any message column if the array is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79eff994-70c7-4bc3-9166-ba8689ea1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after removing empty lists: 4042\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask to select columns with only empty lists\n",
    "removeEmptyMessages = df['messages'].apply(lambda x: x == '[]')\n",
    "\n",
    "# Use the mask to drop the columns with only empty lists\n",
    "df = df.drop(index=df[removeEmptyMessages].index)\n",
    "\n",
    "print(f'Total number of rows after removing empty lists: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee313a6-43a2-4db1-9ce2-9ab1b0f71b31",
   "metadata": {},
   "source": [
    "## Remove JSON and Keep Message Field\n",
    "\n",
    "We will remove the JSON formatting and keep the message field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ed53d14-4f38-4e75-8e92-2ff16779b3d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_226/920307295.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply the function to the 'json' column and create a new 'message' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_message'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_226/920307295.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply the function to the 'json' column and create a new 'message' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_message'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_226/920307295.py\u001b[0m in \u001b[0;36mextract_message\u001b[0;34m(json)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define a function to extract the message field from the JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply the function to the 'json' column and create a new 'message' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Define a function to extract the message field from the JSON\n",
    "def extract_message(json):\n",
    "  return json['message']\n",
    "\n",
    "# Apply the function to the 'json' column and create a new 'message' column\n",
    "df['new_message'] = df['messages'].apply(lambda x: list(map(extract_message, x)))\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc63659-7dff-4795-9fe4-ba01ee7968e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536cb867-d5b4-452e-8d6e-5eeb52e2d729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37a7402-879d-4305-8176-07c80c5cd07a",
   "metadata": {},
   "source": [
    "# Remove unused fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c23bf0e-2645-4d04-b47d-f9577f66485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\n",
      "drwxr-xr-x 4 jovyan users  4096 Jan  1 02:49 .\n",
      "drwxrwxr-x 5 jovyan  1000  4096 Dec 24 19:16 ..\n",
      "drwxr-xr-x 2 jovyan users  4096 Jan  1 02:49 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 jovyan users 12484 Dec 28 17:16 rnn-softmax.ipynb\n",
      "drwxr-xr-x 4 jovyan users  4096 Jan  1 03:22 rnn-softmax-multi-class-text-classify\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fd914-6346-4798-9785-c226cf300d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d1a712-efce-44da-a688-540321074269",
   "metadata": {},
   "source": [
    "# Keep only the message in the JSON."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
